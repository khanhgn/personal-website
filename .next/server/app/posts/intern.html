<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/330ed9d93638ee14.css" data-precedence="next"/><link rel="preload" href="/_next/static/chunks/webpack-250cfe65e386a6ca.js" as="script" fetchPriority="low"/><script src="/_next/static/chunks/fd9d1056-f65ea60ce84a2d9f.js" async=""></script><script src="/_next/static/chunks/596-6f2c4b67f28473ae.js" async=""></script><script src="/_next/static/chunks/main-app-54814a1b80ef1d5b.js" async=""></script><title>How to do Parallel Training | Khanh</title><meta name="description" content="a reflection about my internship at Maptek"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="128x128"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&false)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}else{c.add('dark')}if(e==='light'||e==='dark'||!e)d.style.colorScheme=e||'dark'}catch(e){}}()</script><header class="py-4"><div class="mx-auto max-w-2xl px-6 lg:max-w-4xl"><div class="flex items-center justify-between py-6"><nav class="flex flex-wrap justify-center md:justify-start"><a class="nav-link" href="/">Home</a><a class="nav-link" href="/reading">Readings</a><a class="nav-link" href="/blogs">Blog</a><a class="nav-link hidden md:block" href="/resume">Resume</a><a class="nav-link hidden md:block" href="/transcript">Transcript</a></nav><button type="button" aria-label="Toggle theme" class="group rounded-full bg-white/90 px-3 py-2 shadow-lg shadow-zinc-800/5 ring-1 ring-zinc-900/5 transition dark:bg-zinc-800/90 dark:ring-white/10 dark:hover:ring-white/20"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-6 w-6 fill-zinc-100 stroke-zinc-500 transition group-hover:fill-zinc-200 group-hover:stroke-zinc-700 dark:hidden [@media(prefers-color-scheme:dark)]:fill-zinc-50 [@media(prefers-color-scheme:dark)]:stroke-zinc-500 [@media(prefers-color-scheme:dark)]:group-hover:fill-zinc-50 [@media(prefers-color-scheme:dark)]:group-hover:stroke-zinc-600"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="hidden h-6 w-6 fill-zinc-700 stroke-zinc-500 transition dark:block [@media(prefers-color-scheme:dark)]:group-hover:stroke-zinc-400 [@media_not_(prefers-color-scheme:dark)]:fill-zinc-400/10 [@media_not_(prefers-color-scheme:dark)]:stroke-zinc-500"><path d="M12 3a6 6 0 0 0 9 9 9 9 0 1 1-9-9Z"></path><path d="M19 3v4"></path><path d="M21 5h-4"></path></svg></button></div></div></header><main><div class="mx-auto max-w-2xl px-6 lg:max-w-4xl"><div><h1>How to do Parallel Training</h1><time class="my-4 block text-sm text-zinc-400" dateTime="2024-05-30T00:00:00.000Z">May 30, 2024</time><article class="prose dark:prose-invert"><h1 id="introduction"><a href="#introduction"><span class="icon icon-link"></span></a>Introduction</h1>
<p>Â This report aims to display my work in the internship at Maptek over this semester. To briefly outline the team that I worked with, I collaborated with Maptek&#x27;s DomainMCF team which focuses on using machine learning to produce 3D geological models specifically domain and grades models. My job in this was to make everything run faster. Maptek has the requirement of faster training time and inference for their neural networks which will dramatically boost the customer experience as well as other downstream tasks.
Going into this project, I did not know much other than the fact that I must somehow look through this code base and understand how to make it run faster. The original neural network has been ported from tensorflow to FLAX/JAX recently which already shows a speed increase. However, I would need to make the new FLAX/JAX implementation run even faster.</p>
<h1 id="here-are-the-results"><a href="#here-are-the-results"><span class="icon icon-link"></span></a>Here are the results</h1>
<p>![[image.png]]</p>
<p>The red bar represents the original Tensorflow implementation of the DomainMCF neural network. As demonstrated by the graph, it is quite slow at nearly 1000 seconds to run train a 10 million parameter model over 190 epochs with a batch size of 16384. The green bar shows the FLAX/JAX model, the same neural network programmed on a different deep learning framework which is much better in terms of speed compares to previous frameworks such as PyTorch or Tensorflow. Lets shift our attention towards the parallel models now. In yellow is the Tensorflow model implemented with mirrored strategy - a prebuilt function provided by the Tensorflow library that allows synchronous training across multiple replicas. As expected, it is faster than both the Tensorflow and FLAX on 1 gpu. But what about parallel training on JAX/FLAX. Well, blue and black are my implementations, a near 50% speed up compared to where we started.</p>
<h1 id="so-how-did-i-do-it"><a href="#so-how-did-i-do-it"><span class="icon icon-link"></span></a>So how did I do it.</h1>
<h3 id="lets-start-with-the-basics---what-is-jaxflax"><a href="#lets-start-with-the-basics---what-is-jaxflax"><span class="icon icon-link"></span></a>Let&#x27;s start with the basics - What is JAX/FLAX</h3>
<p>JAX is a machine learning framework that was created by the researchers at Google Deepmind for transforming numerical functions. While FLAX is the accompanying neural network library that is designed with object oriented design in mind. So what does this all mean? JAX runs really really fast. But what is the tradeoff? JAX is pretty hard to approach - particularly for a new comer, not only for its difficult for the functional programming paradigm, the learning curve is steep due to concepts such as JIT (just in time compilation), VMAP (vectorising maps) and shard_map. It also does not help that the JAX documentation is written for someone with some experience in mind. Nevertheless, the first few days of the project involved me sitting down for many hours trying to implement neural networks from scratch using this framework for the first time.</p>
<h3 id="what-were-my-strategies-going-in-to-this"><a href="#what-were-my-strategies-going-in-to-this"><span class="icon icon-link"></span></a>What were my strategies going in to this</h3>
<p>Prior to conducting any work on the large code base given to me from Maptek, I had to plan out carefully which improvements i could make to the code. Here are the few things that I can come up with:</p>
<ol>
<li>The model currently only works on 1 accelerator, what if we need to deploy it on the cloud where there are any number of accelerators?</li>
<li>The loss function is not implemented with vectorising maps (VMAP), will reimplementing it result in a speed up?</li>
<li>How can the GPUs usage vary to maximise performance?</li>
<li>The batch size currently is fixed, this does not maximise GPU usage, how can we find a better batch size? will finding the max batch size result in a speed up?</li>
<li>Let&#x27;s make sure the inference pipeline is parallelised as well.</li>
</ol>
<h3 id="1-training-across-multiple-accelerators"><a href="#1-training-across-multiple-accelerators"><span class="icon icon-link"></span></a>1. Training across multiple accelerators</h3>
<p>After reviewing the training loop, I realised that the 2 components that could be parallelised are the loss function and the gradient computation.</p>
<h4 id="implementation-of-loss-parallelism"><a href="#implementation-of-loss-parallelism"><span class="icon icon-link"></span></a>Implementation of Loss Parallelism:</h4>
<p>When implementing parallel training, I explored various methods:</p>
<ul>
<li>
<p><strong>Data Parallelism:</strong> Divides training data across multiple processors, with each processor working on its subset independently. Gradients are aggregated and averaged for model parameter updates, ideal for large datasets.</p>
</li>
<li>
<p><strong>Model Parallelism:</strong> Distributes different model parts across processors, each handling a segment and computing forward/backward passes. Suitable for very large models exceeding single processor memory limits.</p>
</li>
<li>
<p><strong>Pipeline Parallelism:</strong> Combines data and model parallelism, segmenting the model and assigning segments to processors. Data flows sequentially through these segments, balancing computation and memory usage.</p>
</li>
</ul>
<p>I chose Data Parallelism due to its suitability because unless the model significantly surpasses single GPU capacity, it will not make sense to go for the other techniques. Initially, model parameters are replicated across accelerators. The batch is evenly divided among accelerators for loss computation. The averaged loss is then used for calculating gradients across the model and subsequent updates.</p>
<p>Here is the sample code of a non parallel loss function (not actual code from the project):</p>
<div data-rehype-pretty-code-fragment=""><pre style="background-color:#282c34" tabindex="0" data-language="python" data-theme="default"><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> jax</span></span>
<span data-line=""><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> jax.numpy </span><span style="color:#C678DD">as</span><span style="color:#ABB2BF"> jnp</span></span>
<span data-line=""><span style="color:#61AFEF">@jax</span><span style="color:#ABB2BF">.</span><span style="color:#61AFEF">jit</span></span>
<span data-line=""><span style="color:#C678DD">def</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">loss_fn</span><span style="color:#ABB2BF">(</span><span style="color:#D19A66;font-style:italic">params</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66;font-style:italic">batch</span><span style="color:#ABB2BF">):</span></span>
<span data-line=""><span style="color:#ABB2BF">	inputs, targets </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> batch</span></span>
<span data-line=""><span style="color:#ABB2BF">	predictions </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">predict</span><span style="color:#ABB2BF">(params, inputs)</span></span>
<span data-line=""><span style="color:#ABB2BF">	</span><span style="color:#C678DD">return</span><span style="color:#ABB2BF"> jnp.</span><span style="color:#61AFEF">mean</span><span style="color:#ABB2BF">(jnp.</span><span style="color:#61AFEF">sum</span><span style="color:#ABB2BF">((predictions </span><span style="color:#56B6C2">-</span><span style="color:#ABB2BF"> targets)</span><span style="color:#56B6C2">**</span><span style="color:#D19A66">2</span><span style="color:#ABB2BF">, </span><span style="color:#E06C75;font-style:italic">axis</span><span style="color:#56B6C2">=-</span><span style="color:#D19A66">1</span><span style="color:#ABB2BF">))</span></span></code></pre></div>
<p>Here is the sample code of how we can make it parallel (not actual code from the project):</p>
<div data-rehype-pretty-code-fragment=""><pre style="background-color:#282c34" tabindex="0" data-language="python" data-theme="default"><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#C678DD">from</span><span style="color:#ABB2BF"> functools </span><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> partial</span></span>
<span data-line=""><span style="color:#C678DD">from</span><span style="color:#ABB2BF"> jax.sharding </span><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> NamedSharding, Mesh, PartitionSpec </span><span style="color:#C678DD">as</span><span style="color:#ABB2BF"> P</span></span>
<span data-line=""><span style="color:#C678DD">from</span><span style="color:#ABB2BF"> jax.experimental.shard_map </span><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> shard_map</span></span>
<span data-line=""><span style="color:#C678DD">from</span><span style="color:#ABB2BF"> jax.experimental </span><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> mesh_utils</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#61AFEF">@jax</span><span style="color:#ABB2BF">.</span><span style="color:#61AFEF">jit</span></span>
<span data-line=""><span style="color:#C678DD">def</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">loss_dp</span><span style="color:#ABB2BF">(</span><span style="color:#D19A66;font-style:italic">params</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66;font-style:italic">batch</span><span style="color:#ABB2BF">):</span></span>
<span data-line=""><span style="color:#ABB2BF">	devices </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> mes_utils.</span><span style="color:#61AFEF">create_device_mesh</span><span style="color:#ABB2BF">(</span><span style="color:#D19A66">2</span><span style="color:#ABB2BF">,)</span></span>
<span data-line=""><span style="color:#ABB2BF">	m </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">Mesh</span><span style="color:#ABB2BF">(devices, (</span><span style="color:#98C379">&#x27;batch&#x27;</span><span style="color:#ABB2BF">,))</span></span>
<span data-line=""><span style="color:#61AFEF">	@partial</span><span style="color:#ABB2BF">(</span><span style="color:#61AFEF">shard_map</span><span style="color:#ABB2BF">,</span><span style="color:#61AFEF"> </span><span style="color:#E06C75;font-style:italic">mesh</span><span style="color:#56B6C2">=</span><span style="color:#61AFEF">mesh</span><span style="color:#ABB2BF">,</span><span style="color:#61AFEF"> </span><span style="color:#E06C75;font-style:italic">in_specs</span><span style="color:#56B6C2">=</span><span style="color:#61AFEF">P</span><span style="color:#ABB2BF">(</span><span style="color:#98C379">&#x27;batch&#x27;</span><span style="color:#ABB2BF">,</span><span style="color:#61AFEF"> </span><span style="color:#D19A66">None</span><span style="color:#ABB2BF">),</span><span style="color:#61AFEF"> </span><span style="color:#E06C75;font-style:italic">out_specs</span><span style="color:#56B6C2">=</span><span style="color:#61AFEF">P</span><span style="color:#ABB2BF">())</span></span>
<span data-line=""><span style="color:#ABB2BF">	</span><span style="color:#C678DD">def</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">loss_spmd</span><span style="color:#ABB2BF">(</span><span style="color:#D19A66;font-style:italic">params</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66;font-style:italic">batch</span><span style="color:#ABB2BF">):</span></span>
<span data-line=""><span style="color:#ABB2BF">		batch_local_loss </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">loss_fn</span><span style="color:#ABB2BF">(params, batch)</span></span>
<span data-line=""><span style="color:#ABB2BF">		</span><span style="color:#C678DD">return</span><span style="color:#ABB2BF"> jax.lax.</span><span style="color:#61AFEF">pmean</span><span style="color:#ABB2BF">(batch_local_loss, </span><span style="color:#98C379">&#x27;batch&#x27;</span><span style="color:#ABB2BF">)</span></span>
<span data-line=""><span style="color:#ABB2BF">	</span><span style="color:#C678DD">return</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">loss_spmd</span><span style="color:#ABB2BF">(params, batch)</span></span></code></pre></div>
<p>Optional:</p>
<ul>
<li>These 2 lines are used to explicitly load the accelerators, however, my testing shows that this results in worse performance when compared to JAX&#x27;s own dynamic memory allocation method</li>
</ul>
<div data-rehype-pretty-code-fragment=""><pre style="background-color:#282c34" tabindex="0" data-language="python" data-theme="default"><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#ABB2BF">params </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> jax.</span><span style="color:#61AFEF">device_put</span><span style="color:#ABB2BF">(params, </span><span style="color:#61AFEF">NamedSharding</span><span style="color:#ABB2BF">(mesh, </span><span style="color:#61AFEF">P</span><span style="color:#ABB2BF">()))</span></span>
<span data-line=""><span style="color:#ABB2BF">inputs </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> jax.</span><span style="color:#61AFEF">device_put</span><span style="color:#ABB2BF">(batch, </span><span style="color:#61AFEF">NamedSharding</span><span style="color:#ABB2BF">(mesh, </span><span style="color:#61AFEF">P</span><span style="color:#ABB2BF">(</span><span style="color:#98C379">&#x27;batch&#x27;</span><span style="color:#ABB2BF">)))</span></span></code></pre></div>
<p>Here is a demo of precisely what the method is doing for a batch size of 8 over 2 GPUs:</p>
<p><strong>The batch is divided evenly over 2 GPUs so each gpu should return 4 loss values:</strong></p>
<ul>
<li>
<p>On cuda:0 at mesh coordinates (batch,) = (0,):</p>
<div data-rehype-pretty-code-fragment=""><pre style="background-color:#282c34" tabindex="0" data-language="python" data-theme="default"><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#ABB2BF">[[</span><span style="color:#D19A66">1.2023029</span><span style="color:#ABB2BF"> ]</span></span>
<span data-line=""><span style="color:#ABB2BF"> [</span><span style="color:#D19A66">0.71759206</span><span style="color:#ABB2BF">]</span></span>
<span data-line=""><span style="color:#ABB2BF"> [</span><span style="color:#D19A66">0.29744676</span><span style="color:#ABB2BF">]</span></span>
<span data-line=""><span style="color:#ABB2BF"> [</span><span style="color:#D19A66">0.80767024</span><span style="color:#ABB2BF">]]</span></span></code></pre></div>
</li>
<li>
<p>On cuda:1 at mesh coordinates (batch,) = (1,):</p>
<div data-rehype-pretty-code-fragment=""><pre style="background-color:#282c34" tabindex="0" data-language="python" data-theme="default"><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#ABB2BF">[[</span><span style="color:#D19A66">0.7249529</span><span style="color:#ABB2BF"> ]</span></span>
<span data-line=""><span style="color:#ABB2BF"> [</span><span style="color:#D19A66">1.2052361</span><span style="color:#ABB2BF"> ]</span></span>
<span data-line=""><span style="color:#ABB2BF"> [</span><span style="color:#D19A66">0.80882186</span><span style="color:#ABB2BF">]</span></span>
<span data-line=""><span style="color:#ABB2BF"> [</span><span style="color:#D19A66">0.7385298</span><span style="color:#ABB2BF"> ]]</span></span></code></pre></div>
</li>
</ul>
<p><strong>On each gpu the loss values calculated is average to get the local loss:</strong></p>
<ul>
<li>
<p>On cuda:0 at mesh coordinates (batch,) = (0,):</p>
<div data-rehype-pretty-code-fragment=""><pre style="background-color:#282c34" tabindex="0" data-language="python" data-theme="default"><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#D19A66">0.7562530040740967</span></span></code></pre></div>
</li>
<li>
<p>On cuda:1 at mesh coordinates (batch,) = (1,):</p>
<div data-rehype-pretty-code-fragment=""><pre style="background-color:#282c34" tabindex="0" data-language="python" data-theme="default"><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#D19A66">0.8693851232528687</span></span></code></pre></div>
</li>
</ul>
<p><strong><code>pmean</code> is performed over 2 gpus to get the average loss for that batch of 8:</strong></p>
<ul>
<li>
<p>On cuda:0 at mesh coordinates (batch,) = (0,):</p>
<div data-rehype-pretty-code-fragment=""><pre style="background-color:#282c34" tabindex="0" data-language="python" data-theme="default"><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#D19A66">0.8128190636634827</span></span></code></pre></div>
</li>
<li>
<p>On cuda:1 at mesh coordinates (batch,) = (1,):</p>
<div data-rehype-pretty-code-fragment=""><pre style="background-color:#282c34" tabindex="0" data-language="python" data-theme="default"><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#D19A66">0.8128190636634827</span></span></code></pre></div>
</li>
</ul>
<p><strong>Final Loss returned by function:</strong></p>
<div data-rehype-pretty-code-fragment=""><pre style="background-color:#282c34" tabindex="0" data-language="python" data-theme="default"><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#D19A66">0.81281906</span></span></code></pre></div>
<h4 id="implementation-of-gradients-parallelism"><a href="#implementation-of-gradients-parallelism"><span class="icon icon-link"></span></a>Implementation of Gradients Parallelism:</h4>
<p>For enhanced efficiency, I parallelised gradients calculation. Before gathering and averaging loss, gradients are independently computed on each GPU. Finally, the average gradients are used for the final update.</p>
<p>Here is the sample code (not from Maptek&#x27;s codebase):</p>
<div data-rehype-pretty-code-fragment=""><pre style="background-color:#282c34" tabindex="0" data-language="python" data-theme="default"><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#C678DD">from</span><span style="color:#ABB2BF"> functools </span><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> partial</span></span>
<span data-line=""><span style="color:#C678DD">from</span><span style="color:#ABB2BF"> jax.sharding </span><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> NamedSharding, Mesh, PartitionSpec </span><span style="color:#C678DD">as</span><span style="color:#ABB2BF"> P</span></span>
<span data-line=""><span style="color:#C678DD">from</span><span style="color:#ABB2BF"> jax.experimental.shard_map </span><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> shard_map</span></span>
<span data-line=""><span style="color:#C678DD">from</span><span style="color:#ABB2BF"> jax.experimental </span><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> mesh_utils</span></span>
<span data-line=""><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> jax</span></span>
<span data-line=""><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> jax.numpy </span><span style="color:#C678DD">as</span><span style="color:#ABB2BF"> jnp</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#61AFEF">@jax</span><span style="color:#ABB2BF">.</span><span style="color:#61AFEF">jit</span></span>
<span data-line=""><span style="color:#C678DD">def</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">loss_fn</span><span style="color:#ABB2BF">(</span><span style="color:#D19A66;font-style:italic">params</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66;font-style:italic">batch</span><span style="color:#ABB2BF">):</span></span>
<span data-line=""><span style="color:#ABB2BF">	inputs, targets </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> batch</span></span>
<span data-line=""><span style="color:#ABB2BF">	predictions </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">predict</span><span style="color:#ABB2BF">(params, inputs)</span></span>
<span data-line=""><span style="color:#ABB2BF">	</span><span style="color:#C678DD">return</span><span style="color:#ABB2BF"> jnp.</span><span style="color:#61AFEF">mean</span><span style="color:#ABB2BF">(jnp.</span><span style="color:#61AFEF">sum</span><span style="color:#ABB2BF">((predictions </span><span style="color:#56B6C2">-</span><span style="color:#ABB2BF"> targets)</span><span style="color:#56B6C2">**</span><span style="color:#D19A66">2</span><span style="color:#ABB2BF">, </span><span style="color:#E06C75;font-style:italic">axis</span><span style="color:#56B6C2">=-</span><span style="color:#D19A66">1</span><span style="color:#ABB2BF">))</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#61AFEF">@jax</span><span style="color:#ABB2BF">.</span><span style="color:#61AFEF">jit</span></span>
<span data-line=""><span style="color:#C678DD">def</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">get_loss_gradients</span><span style="color:#ABB2BF">(</span><span style="color:#D19A66;font-style:italic">params</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66;font-style:italic">batch</span><span style="color:#ABB2BF">):</span></span>
<span data-line=""><span style="color:#ABB2BF">	devices </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> mes_utils.</span><span style="color:#61AFEF">create_device_mesh</span><span style="color:#ABB2BF">(</span><span style="color:#D19A66">2</span><span style="color:#ABB2BF">,)</span></span>
<span data-line=""><span style="color:#ABB2BF">	m </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">Mesh</span><span style="color:#ABB2BF">(devices, (</span><span style="color:#98C379">&#x27;batch&#x27;</span><span style="color:#ABB2BF">,))</span></span>
<span data-line=""><span style="color:#61AFEF">	@partial</span><span style="color:#ABB2BF">(</span><span style="color:#61AFEF">shard_map</span><span style="color:#ABB2BF">,</span><span style="color:#61AFEF"> </span><span style="color:#E06C75;font-style:italic">mesh</span><span style="color:#56B6C2">=</span><span style="color:#61AFEF">mesh</span><span style="color:#ABB2BF">,</span><span style="color:#61AFEF"> </span><span style="color:#E06C75;font-style:italic">in_specs</span><span style="color:#56B6C2">=</span><span style="color:#61AFEF">P</span><span style="color:#ABB2BF">(</span><span style="color:#98C379">&#x27;batch&#x27;</span><span style="color:#ABB2BF">,</span><span style="color:#61AFEF"> </span><span style="color:#D19A66">None</span><span style="color:#ABB2BF">),</span><span style="color:#61AFEF"> </span><span style="color:#E06C75;font-style:italic">out_specs</span><span style="color:#56B6C2">=</span><span style="color:#61AFEF">P</span><span style="color:#ABB2BF">())</span></span>
<span data-line=""><span style="color:#ABB2BF">	</span><span style="color:#C678DD">def</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">parallel_loss_and_gradients</span><span style="color:#ABB2BF">(</span><span style="color:#D19A66;font-style:italic">params</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66;font-style:italic">batch</span><span style="color:#ABB2BF">):</span></span>
<span data-line=""><span style="color:#ABB2BF">		loss_local, grads_local </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> jax.</span><span style="color:#61AFEF">value_and_grad</span><span style="color:#ABB2BF">(loss_fn)(params,batch)</span></span>
<span data-line=""><span style="color:#ABB2BF">		loss </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> jax.lax.</span><span style="color:#61AFEF">pmean</span><span style="color:#ABB2BF">(loss_local, </span><span style="color:#98C379">&#x27;batch&#x27;</span><span style="color:#ABB2BF">)</span></span>
<span data-line=""><span style="color:#ABB2BF">		grads </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> jax.lax.</span><span style="color:#61AFEF">pmean</span><span style="color:#ABB2BF">(grads_local, </span><span style="color:#98C379">&#x27;batch&#x27;</span><span style="color:#ABB2BF">)</span></span>
<span data-line=""><span style="color:#ABB2BF">		</span><span style="color:#C678DD">return</span><span style="color:#ABB2BF"> loss, grads</span></span>
<span data-line=""><span style="color:#ABB2BF">	</span><span style="color:#C678DD">return</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">parallel_loss_and_gradients</span><span style="color:#ABB2BF">(params, batch)</span></span></code></pre></div>
<p>Notice that the <code>value_and_grad</code> function is nested inside of a <code>shard_map</code>. This means that no explicit sharding of the <code>loss_fn</code> function is required.</p>
<div data-rehype-pretty-code-fragment=""><pre style="background-color:#282c34" tabindex="0" data-language="python" data-theme="default"><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#61AFEF">@partial</span><span style="color:#ABB2BF">(</span><span style="color:#61AFEF">shard_map</span><span style="color:#ABB2BF">,</span><span style="color:#61AFEF"> </span><span style="color:#E06C75;font-style:italic">mesh</span><span style="color:#56B6C2">=</span><span style="color:#61AFEF">mesh</span><span style="color:#ABB2BF">,</span><span style="color:#61AFEF"> </span><span style="color:#E06C75;font-style:italic">in_specs</span><span style="color:#56B6C2">=</span><span style="color:#61AFEF">P</span><span style="color:#ABB2BF">(</span><span style="color:#98C379">&#x27;batch&#x27;</span><span style="color:#ABB2BF">,</span><span style="color:#61AFEF"> </span><span style="color:#D19A66">None</span><span style="color:#ABB2BF">),</span><span style="color:#61AFEF"> </span><span style="color:#E06C75;font-style:italic">out_specs</span><span style="color:#56B6C2">=</span><span style="color:#61AFEF">P</span><span style="color:#ABB2BF">())</span></span>
<span data-line=""><span style="color:#ABB2BF">	</span><span style="color:#C678DD">def</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">parallel_loss_and_gradients</span><span style="color:#ABB2BF">(</span><span style="color:#D19A66;font-style:italic">params</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66;font-style:italic">batch</span><span style="color:#ABB2BF">):</span></span>
<span data-line=""><span style="color:#ABB2BF">		loss_local, grads_local </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> jax.</span><span style="color:#61AFEF">value_and_grad</span><span style="color:#ABB2BF">(loss_fn)(params,batch)</span></span>
<span data-line=""><span style="color:#ABB2BF">		loss </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> jax.lax.</span><span style="color:#61AFEF">pmean</span><span style="color:#ABB2BF">(loss_local, </span><span style="color:#98C379">&#x27;batch&#x27;</span><span style="color:#ABB2BF">)</span></span>
<span data-line=""><span style="color:#ABB2BF">		grads </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> jax.lax.</span><span style="color:#61AFEF">pmean</span><span style="color:#ABB2BF">(grads_local, </span><span style="color:#98C379">&#x27;batch&#x27;</span><span style="color:#ABB2BF">)</span></span>
<span data-line=""><span style="color:#ABB2BF">		</span><span style="color:#C678DD">return</span><span style="color:#ABB2BF"> loss, grads</span></span>
<span data-line=""><span style="color:#ABB2BF">	</span><span style="color:#C678DD">return</span><span style="color:#ABB2BF"> </span><span style="color:#61AFEF">parallel_loss_and_gradients</span><span style="color:#ABB2BF">(params, batch)</span><span style="color:#FFFFFF">```</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#ABB2BF">Here </span><span style="color:#C678DD">is</span><span style="color:#ABB2BF"> a demo of what this method </span><span style="color:#C678DD">is</span><span style="color:#ABB2BF"> doing to a </span><span style="color:#D19A66">81</span><span style="color:#ABB2BF"> parameter network.</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#56B6C2">**</span><span style="color:#ABB2BF">Data Labels:</span><span style="color:#56B6C2">**</span></span>
<span data-line=""><span style="color:#56B6C2">-</span><span style="color:#ABB2BF"> </span><span style="color:#FFFFFF">`data_labels`</span><span style="color:#ABB2BF">: (</span><span style="color:#D19A66">2</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">64</span><span style="color:#ABB2BF">)</span></span>
<span data-line=""><span style="color:#56B6C2">-</span><span style="color:#ABB2BF"> </span><span style="color:#FFFFFF">`data_inputs`</span><span style="color:#ABB2BF">: (</span><span style="color:#D19A66">128</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">2</span><span style="color:#ABB2BF">)</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#56B6C2">**</span><span style="color:#61AFEF">Sharded</span><span style="color:#ABB2BF"> (what each </span><span style="color:#D19A66">GPU</span><span style="color:#ABB2BF"> gets):</span><span style="color:#56B6C2">**</span></span>
<span data-line=""><span style="color:#56B6C2">-</span><span style="color:#ABB2BF"> </span><span style="color:#FFFFFF">`data_labels`</span><span style="color:#ABB2BF">: (</span><span style="color:#D19A66">64</span><span style="color:#ABB2BF">,)</span></span>
<span data-line=""><span style="color:#56B6C2">-</span><span style="color:#ABB2BF"> </span><span style="color:#FFFFFF">`data_inputs`</span><span style="color:#ABB2BF">: (</span><span style="color:#D19A66">64</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">2</span><span style="color:#ABB2BF">)</span></span>
<span data-line=""> </span>
<span data-line=""><span style="color:#56B6C2">**</span><span style="color:#ABB2BF">Before pmean:</span><span style="color:#56B6C2">**</span></span>
<span data-line=""><span style="color:#FFFFFF">```python</span></span>
<span data-line=""><span style="color:#ABB2BF">{</span></span>
<span data-line=""><span style="color:#ABB2BF">    </span><span style="color:#98C379">&#x27;params&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">        </span><span style="color:#98C379">&#x27;Dense_0&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">            </span><span style="color:#98C379">&#x27;bias&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:0 at mesh coordinates (batch,) = (0,)&#x27;</span><span style="color:#ABB2BF">: [</span><span style="color:#D19A66">0.00814706</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">0.06351265</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">0.13132916</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">],</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:1 at mesh coordinates (batch,) = (1,)&#x27;</span><span style="color:#ABB2BF">: [</span><span style="color:#D19A66">0.00723927</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">0.05536034</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">0.11896412</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">]</span></span>
<span data-line=""><span style="color:#ABB2BF">            },</span></span>
<span data-line=""><span style="color:#ABB2BF">            </span><span style="color:#98C379">&#x27;kernel&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:0 at mesh coordinates (batch,) = (0,)&#x27;</span><span style="color:#ABB2BF">: [[</span><span style="color:#D19A66">3.15032015e-03</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">2.28520837e-02</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">], [</span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">]],</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:1 at mesh coordinates (batch,) = (1,)&#x27;</span><span style="color:#ABB2BF">: [[</span><span style="color:#D19A66">3.8428977e-03</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">2.7929787e-02</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">], [</span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">]]</span></span>
<span data-line=""><span style="color:#ABB2BF">            }</span></span>
<span data-line=""><span style="color:#ABB2BF">        },</span></span>
<span data-line=""><span style="color:#ABB2BF">        </span><span style="color:#98C379">&#x27;Dense_1&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">            </span><span style="color:#98C379">&#x27;bias&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:0 at mesh coordinates (batch,) = (0,)&#x27;</span><span style="color:#ABB2BF">: [</span><span style="color:#D19A66">0.358499</span><span style="color:#ABB2BF">],</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:1 at mesh coordinates (batch,) = (1,)&#x27;</span><span style="color:#ABB2BF">: [</span><span style="color:#D19A66">0.33250016</span><span style="color:#ABB2BF">]</span></span>
<span data-line=""><span style="color:#ABB2BF">            },</span></span>
<span data-line=""><span style="color:#ABB2BF">            </span><span style="color:#98C379">&#x27;kernel&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:0 at mesh coordinates (batch,) = (0,)&#x27;</span><span style="color:#ABB2BF">: [[</span><span style="color:#56B6C2">-</span><span style="color:#D19A66">8.91311318e-02</span><span style="color:#ABB2BF">], [</span><span style="color:#56B6C2">-</span><span style="color:#D19A66">1.09796718e-01</span><span style="color:#ABB2BF">], </span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">],</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:1 at mesh coordinates (batch,) = (1,)&#x27;</span><span style="color:#ABB2BF">: [[</span><span style="color:#56B6C2">-</span><span style="color:#D19A66">0.10461892</span><span style="color:#ABB2BF">], [</span><span style="color:#56B6C2">-</span><span style="color:#D19A66">0.12866098</span><span style="color:#ABB2BF">], </span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">]</span></span>
<span data-line=""><span style="color:#ABB2BF">            }</span></span>
<span data-line=""><span style="color:#ABB2BF">        }</span></span>
<span data-line=""><span style="color:#ABB2BF">    }</span></span>
<span data-line=""><span style="color:#ABB2BF">}</span></span></code></pre></div>
<p><strong>After pmean:</strong></p>
<div data-rehype-pretty-code-fragment=""><pre style="background-color:#282c34" tabindex="0" data-language="python" data-theme="default"><code data-language="python" data-theme="default" style="display:grid"><span data-line=""><span style="color:#ABB2BF">{</span></span>
<span data-line=""><span style="color:#ABB2BF">    </span><span style="color:#98C379">&#x27;params&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">        </span><span style="color:#98C379">&#x27;Dense_0&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">            </span><span style="color:#98C379">&#x27;bias&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:0 at mesh coordinates (batch,) = (0,)&#x27;</span><span style="color:#ABB2BF">: [</span><span style="color:#D19A66">0.00769317</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">0.05943649</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">0.12514664</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">],</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:1 at mesh coordinates (batch,) = (1,)&#x27;</span><span style="color:#ABB2BF">: [</span><span style="color:#D19A66">0.00769317</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">0.05943649</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">0.12514664</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">]</span></span>
<span data-line=""><span style="color:#ABB2BF">            },</span></span>
<span data-line=""><span style="color:#ABB2BF">            </span><span style="color:#98C379">&#x27;kernel&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:0 at mesh coordinates (batch,) = (0,)&#x27;</span><span style="color:#ABB2BF">: [[</span><span style="color:#D19A66">3.4966089e-03</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">2.5390934e-02</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">], [</span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">]],</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:1 at mesh coordinates (batch,) = (1,)&#x27;</span><span style="color:#ABB2BF">: [[</span><span style="color:#D19A66">3.4966089e-03</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">2.5390934e-02</span><span style="color:#ABB2BF">, </span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">], [</span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">]]</span></span>
<span data-line=""><span style="color:#ABB2BF">            }</span></span>
<span data-line=""><span style="color:#ABB2BF">        },</span></span>
<span data-line=""><span style="color:#ABB2BF">        </span><span style="color:#98C379">&#x27;Dense_1&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">            </span><span style="color:#98C379">&#x27;bias&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:0 at mesh coordinates (batch,) = (0,)&#x27;</span><span style="color:#ABB2BF">: [</span><span style="color:#D19A66">0.34549958</span><span style="color:#ABB2BF">],</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:1 at mesh coordinates (batch,) = (1,)&#x27;</span><span style="color:#ABB2BF">: [</span><span style="color:#D19A66">0.34549958</span><span style="color:#ABB2BF">]</span></span>
<span data-line=""><span style="color:#ABB2BF">            },</span></span>
<span data-line=""><span style="color:#ABB2BF">            </span><span style="color:#98C379">&#x27;kernel&#x27;</span><span style="color:#ABB2BF">: {</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:0 at mesh coordinates (batch,) = (0,)&#x27;</span><span style="color:#ABB2BF">: [[</span><span style="color:#56B6C2">-</span><span style="color:#D19A66">0.09687503</span><span style="color:#ABB2BF">], [</span><span style="color:#56B6C2">-</span><span style="color:#D19A66">0.11922885</span><span style="color:#ABB2BF">], </span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">],</span></span>
<span data-line=""><span style="color:#ABB2BF">                </span><span style="color:#98C379">&#x27;On cuda:1 at mesh coordinates (batch,) = (1,)&#x27;</span><span style="color:#ABB2BF">: [[</span><span style="color:#56B6C2">-</span><span style="color:#D19A66">0.09687503</span><span style="color:#ABB2BF">], [</span><span style="color:#56B6C2">-</span><span style="color:#D19A66">0.11922885</span><span style="color:#ABB2BF">], </span><span style="color:#D19A66">...</span><span style="color:#ABB2BF">]</span></span>
<span data-line=""><span style="color:#ABB2BF">            }</span></span>
<span data-line=""><span style="color:#ABB2BF">        }</span></span>
<span data-line=""><span style="color:#ABB2BF">    }</span></span>
<span data-line=""><span style="color:#ABB2BF">}</span></span></code></pre></div>
<h3 id="2-implementation-of-vectorising-maps"><a href="#2-implementation-of-vectorising-maps"><span class="icon icon-link"></span></a>2. Implementation of Vectorising Maps:</h3>
<p>Efforts were made to re-implement the loss function using vectorising maps to boost speed. However, no significant improvement was observed compared to native batched operations. VMAPs also consumed more memory in certain cases, leading to a shift back to native operations.</p>
<h3 id="3-implementation-of-dynamic-gpu-utilisation"><a href="#3-implementation-of-dynamic-gpu-utilisation"><span class="icon icon-link"></span></a>3. Implementation of Dynamic GPU Utilisation:</h3>
<p>Considering varying GPU architectures and quantities, I implemented functions to dynamically allocate data. This is crucial, especially for the last training step when the final batch size might differ from the predetermined size. This serves two cases: sending the last bit of data to a single GPU if it fits, or performing a search for the optimal number of GPUs for computation if it doesn&#x27;t.</p>
<p>JAX&#x27;s high controllability comes with the cost of having to implement a lot of the things that Tensorflow automate manually. For example, if we have 4 accelerators and the last batch is odd, this will cause the entire program to fail. The way that we could combat this is to have a check function implemented where we dynamically find the optimal number of accelerators that would fit the current batch size. This is simply implemented using for loops, if statements and also using the modulo operator to determine if the batch would work with a certain amount of accelerators.</p>
<h3 id="4-implementation-of-batch_size-initialisation"><a href="#4-implementation-of-batch_size-initialisation"><span class="icon icon-link"></span></a>4. Implementation of batch_size Initialisation:</h3>
<p>The idea behind this segment is that speed should increase as the batch size that is being handled by each GPU is increased. Because of this, I have derived a function to dynamically calculate the maximum batch size that each GPU can handle. factors considered include GPU architecture, model and optimizer sizes, and data shape. This ensures maximum performance across different models and machines.</p>
<h4 id="note-making-the-losses-of-the-flax-model-coherent"><a href="#note-making-the-losses-of-the-flax-model-coherent"><span class="icon icon-link"></span></a>Note: Making the Losses of the Flax Model Coherent</h4>
<p>To ensure consistent comparisons, every randomized aspect of the Flax model is assigned a coherent seed. However, attempts to make TensorFlow model loss coherent by seeding the data generator did not yield consistent results. This indicates internal TensorFlow parameters not being consistently initialized, resulting in varying loss compared to Flax models. As a result of this, while the speed up produced by my work is backed up by the graph produced, further work is needed to investigate the state of the Tensorflow model.</p></article></div></div></main><footer class="py-16"><div class="mx-auto max-w-2xl px-6 lg:max-w-4xl"><p>Built by<!-- --> <a class="link" href="https://twitter.com/khanhgng">Khanh Nguyen</a><br/><a class="link" href="https://twitter.com/khanhgng">*inspired by Leerob</a></p></div></footer><script src="/_next/static/chunks/webpack-250cfe65e386a6ca.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/330ed9d93638ee14.css\",{\"as\":\"style\"}]\n0:\"$L2\"\n"])</script><script>self.__next_f.push([1,"3:I{\"id\":7948,\"chunks\":[\"272:static/chunks/webpack-250cfe65e386a6ca.js\",\"971:static/chunks/fd9d1056-f65ea60ce84a2d9f.js\",\"596:static/chunks/596-6f2c4b67f28473ae.js\"],\"name\":\"default\",\"async\":false}\n5:I{\"id\":6628,\"chunks\":[\"272:static/chunks/webpack-250cfe65e386a6ca.js\",\"971:static/chunks/fd9d1056-f65ea60ce84a2d9f.js\",\"596:static/chunks/596-6f2c4b67f28473ae.js\"],\"name\":\"\",\"async\":false}\n6:I{\"id\":4129,\"chunks\":[\"685:static/chunks/685-e838ada71756f796.js\",\"185:static/chunks/app/layout-dbfce196e10d0a24.js\"],\"na"])</script><script>self.__next_f.push([1,"me\":\"ThemeProvider\",\"async\":false}\n7:I{\"id\":6685,\"chunks\":[\"685:static/chunks/685-e838ada71756f796.js\",\"222:static/chunks/222-f2de100879ad0210.js\",\"333:static/chunks/app/posts/[slug]/page-fc4f275fd7cb064c.js\"],\"name\":\"\",\"async\":false}\n8:I{\"id\":4001,\"chunks\":[\"685:static/chunks/685-e838ada71756f796.js\",\"185:static/chunks/app/layout-dbfce196e10d0a24.js\"],\"name\":\"\",\"async\":false}\n9:I{\"id\":7767,\"chunks\":[\"272:static/chunks/webpack-250cfe65e386a6ca.js\",\"971:static/chunks/fd9d1056-f65ea60ce84a2d9f.js\",\"596:static"])</script><script>self.__next_f.push([1,"/chunks/596-6f2c4b67f28473ae.js\"],\"name\":\"default\",\"async\":false}\na:I{\"id\":7920,\"chunks\":[\"272:static/chunks/webpack-250cfe65e386a6ca.js\",\"971:static/chunks/fd9d1056-f65ea60ce84a2d9f.js\",\"596:static/chunks/596-6f2c4b67f28473ae.js\"],\"name\":\"default\",\"async\":false}\n"])</script><script>self.__next_f.push([1,"2:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/330ed9d93638ee14.css\",\"precedence\":\"next\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"O_Hy9gwwvHeNSmxjozlmr\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/posts/intern\",\"initialTree\":[\"\",{\"children\":[\"posts\",{\"children\":[[\"slug\",\"intern\",\"d\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":\\\"intern\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialHead\":[false,\"$L4\"],\"globalErrorComponent\":\"$5\",\"children\":[null,[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"$L6\",null,{\"attribute\":\"class\",\"defaultTheme\":\"dark\",\"children\":[[\"$\",\"header\",null,{\"className\":\"py-4\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-2xl px-6 lg:max-w-4xl\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex items-center justify-between py-6\",\"children\":[[\"$\",\"nav\",null,{\"className\":\"flex flex-wrap justify-center md:justify-start\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"/\",\"className\":\"nav-link\",\"children\":\"Home\"}],[\"$\",\"$L7\",null,{\"href\":\"/reading\",\"className\":\"nav-link\",\"children\":\"Readings\"}],[\"$\",\"$L7\",null,{\"href\":\"/blogs\",\"className\":\"nav-link\",\"children\":\"Blog\"}],[\"$\",\"$L7\",null,{\"href\":\"/resume\",\"className\":\"nav-link hidden md:block\",\"children\":\"Resume\"}],[\"$\",\"$L7\",null,{\"href\":\"/transcript\",\"className\":\"nav-link hidden md:block\",\"children\":\"Transcript\"}]]}],[\"$\",\"$L8\",null,{}]]}]}]}],[\"$\",\"main\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-2xl px-6 lg:max-w-4xl\",\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"childProp\":{\"current\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"posts\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"childProp\":{\"current\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"posts\",\"children\",[\"slug\",\"intern\",\"d\"],\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"childProp\":{\"current\":[\"$Lb\",[\"$\",\"div\",null,{\"children\":[[\"$\",\"h1\",null,{\"children\":\"How to do Parallel Training\"}],[\"$\",\"time\",null,{\"className\":\"my-4 block text-sm text-zinc-400\",\"dateTime\":\"2024-05-30T00:00:00.000Z\",\"children\":\"May 30, 2024\"}],[\"$\",\"article\",null,{\"className\":\"prose dark:prose-invert\",\"children\":[[\"$\",\"h1\",null,{\"id\":\"introduction\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"#introduction\",\"children\":[\"$\",\"span\",null,{\"className\":\"icon icon-link\"}]}],\"Introduction\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Â This report aims to display my work in the internship at Maptek over this semester. To briefly outline the team that I worked with, I collaborated with Maptek's DomainMCF team which focuses on using machine learning to produce 3D geological models specifically domain and grades models. My job in this was to make everything run faster. Maptek has the requirement of faster training time and inference for their neural networks which will dramatically boost the customer experience as well as other downstream tasks.\\nGoing into this project, I did not know much other than the fact that I must somehow look through this code base and understand how to make it run faster. The original neural network has been ported from tensorflow to FLAX/JAX recently which already shows a speed increase. However, I would need to make the new FLAX/JAX implementation run even faster.\"}],\"\\n\",[\"$\",\"h1\",null,{\"id\":\"here-are-the-results\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"#here-are-the-results\",\"children\":[\"$\",\"span\",null,{\"className\":\"icon icon-link\"}]}],\"Here are the results\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"![[image.png]]\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The red bar represents the original Tensorflow implementation of the DomainMCF neural network. As demonstrated by the graph, it is quite slow at nearly 1000 seconds to run train a 10 million parameter model over 190 epochs with a batch size of 16384. The green bar shows the FLAX/JAX model, the same neural network programmed on a different deep learning framework which is much better in terms of speed compares to previous frameworks such as PyTorch or Tensorflow. Lets shift our attention towards the parallel models now. In yellow is the Tensorflow model implemented with mirrored strategy - a prebuilt function provided by the Tensorflow library that allows synchronous training across multiple replicas. As expected, it is faster than both the Tensorflow and FLAX on 1 gpu. But what about parallel training on JAX/FLAX. Well, blue and black are my implementations, a near 50% speed up compared to where we started.\"}],\"\\n\",[\"$\",\"h1\",null,{\"id\":\"so-how-did-i-do-it\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"#so-how-did-i-do-it\",\"children\":[\"$\",\"span\",null,{\"className\":\"icon icon-link\"}]}],\"So how did I do it.\"]}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"lets-start-with-the-basics---what-is-jaxflax\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"#lets-start-with-the-basics---what-is-jaxflax\",\"children\":[\"$\",\"span\",null,{\"className\":\"icon icon-link\"}]}],\"Let's start with the basics - What is JAX/FLAX\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"JAX is a machine learning framework that was created by the researchers at Google Deepmind for transforming numerical functions. While FLAX is the accompanying neural network library that is designed with object oriented design in mind. So what does this all mean? JAX runs really really fast. But what is the tradeoff? JAX is pretty hard to approach - particularly for a new comer, not only for its difficult for the functional programming paradigm, the learning curve is steep due to concepts such as JIT (just in time compilation), VMAP (vectorising maps) and shard_map. It also does not help that the JAX documentation is written for someone with some experience in mind. Nevertheless, the first few days of the project involved me sitting down for many hours trying to implement neural networks from scratch using this framework for the first time.\"}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"what-were-my-strategies-going-in-to-this\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"#what-were-my-strategies-going-in-to-this\",\"children\":[\"$\",\"span\",null,{\"className\":\"icon icon-link\"}]}],\"What were my strategies going in to this\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Prior to conducting any work on the large code base given to me from Maptek, I had to plan out carefully which improvements i could make to the code. Here are the few things that I can come up with:\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"The model currently only works on 1 accelerator, what if we need to deploy it on the cloud where there are any number of accelerators?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"The loss function is not implemented with vectorising maps (VMAP), will reimplementing it result in a speed up?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"How can the GPUs usage vary to maximise performance?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"The batch size currently is fixed, this does not maximise GPU usage, how can we find a better batch size? will finding the max batch size result in a speed up?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Let's make sure the inference pipeline is parallelised as well.\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"1-training-across-multiple-accelerators\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"#1-training-across-multiple-accelerators\",\"children\":[\"$\",\"span\",null,{\"className\":\"icon icon-link\"}]}],\"1. Training across multiple accelerators\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"After reviewing the training loop, I realised that the 2 components that could be parallelised are the loss function and the gradient computation.\"}],\"\\n\",[\"$\",\"h4\",null,{\"id\":\"implementation-of-loss-parallelism\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"#implementation-of-loss-parallelism\",\"children\":[\"$\",\"span\",null,{\"className\":\"icon icon-link\"}]}],\"Implementation of Loss Parallelism:\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"When implementing parallel training, I explored various methods:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Data Parallelism:\"}],\" Divides training data across multiple processors, with each processor working on its subset independently. Gradients are aggregated and averaged for model parameter updates, ideal for large datasets.\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Model Parallelism:\"}],\" Distributes different model parts across processors, each handling a segment and computing forward/backward passes. Suitable for very large models exceeding single processor memory limits.\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Pipeline Parallelism:\"}],\" Combines data and model parallelism, segmenting the model and assigning segments to processors. Data flows sequentially through these segments, balancing computation and memory usage.\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"I chose Data Parallelism due to its suitability because unless the model significantly surpasses single GPU capacity, it will not make sense to go for the other techniques. Initially, model parameters are replicated across accelerators. The batch is evenly divided among accelerators for loss computation. The averaged loss is then used for calculating gradients across the model and subsequent updates.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Here is the sample code of a non parallel loss function (not actual code from the project):\"}],\"\\n\",[\"$\",\"div\",null,{\"data-rehype-pretty-code-fragment\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#282c34\"},\"tabIndex\":\"0\",\"data-language\":\"python\",\"data-theme\":\"default\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"python\",\"data-theme\":\"default\",\"style\":{\"display\":\"grid\"},\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"import\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"import\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.numpy \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"as\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jnp\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"@jax\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\".\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"jit\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"def\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"loss_fn\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"params\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"batch\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"):\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\tinputs, targets \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" batch\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\tpredictions \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"predict\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(params, inputs)\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"return\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jnp.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"mean\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(jnp.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"sum\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"((predictions \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" targets)\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"**\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"2\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#E06C75\",\"fontStyle\":\"italic\"},\"children\":\"axis\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"1\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"))\"}]]}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Here is the sample code of how we can make it parallel (not actual code from the project):\"}],\"\\n\",[\"$\",\"div\",null,{\"data-rehype-pretty-code-fragment\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#282c34\"},\"tabIndex\":\"0\",\"data-language\":\"python\",\"data-theme\":\"default\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"python\",\"data-theme\":\"default\",\"style\":{\"display\":\"grid\"},\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"from\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" functools \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"import\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" partial\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"from\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.sharding \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"import\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" NamedSharding, Mesh, PartitionSpec \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"as\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" P\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"from\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.experimental.shard_map \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"import\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" shard_map\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"from\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.experimental \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"import\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" mesh_utils\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":\" \"}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"@jax\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\".\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"jit\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"def\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"loss_dp\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"params\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"batch\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"):\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\tdevices \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" mes_utils.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"create_device_mesh\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"2\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",)\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\tm \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"Mesh\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(devices, (\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'batch'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",))\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"\\t@partial\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"shard_map\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#E06C75\",\"fontStyle\":\"italic\"},\"children\":\"mesh\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"mesh\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#E06C75\",\"fontStyle\":\"italic\"},\"children\":\"in_specs\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"P\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'batch'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"None\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"),\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#E06C75\",\"fontStyle\":\"italic\"},\"children\":\"out_specs\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"P\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"())\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"def\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"loss_spmd\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"params\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"batch\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"):\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\\tbatch_local_loss \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"loss_fn\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(params, batch)\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\\t\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"return\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.lax.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"pmean\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(batch_local_loss, \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'batch'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\")\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"return\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"loss_spmd\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(params, batch)\"}]]}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Optional:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"These 2 lines are used to explicitly load the accelerators, however, my testing shows that this results in worse performance when compared to JAX's own dynamic memory allocation method\"}],\"\\n\"]}],\"\\n\",[\"$\",\"div\",null,{\"data-rehype-pretty-code-fragment\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#282c34\"},\"tabIndex\":\"0\",\"data-language\":\"python\",\"data-theme\":\"default\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"python\",\"data-theme\":\"default\",\"style\":{\"display\":\"grid\"},\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"params \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"device_put\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(params, \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"NamedSharding\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(mesh, \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"P\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"()))\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"inputs \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"device_put\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(batch, \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"NamedSharding\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(mesh, \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"P\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'batch'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\")))\"}]]}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Here is a demo of precisely what the method is doing for a batch size of 8 over 2 GPUs:\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"The batch is divided evenly over 2 GPUs so each gpu should return 4 loss values:\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"On cuda:0 at mesh coordinates (batch,) = (0,):\"}],\"\\n\",[\"$\",\"div\",null,{\"data-rehype-pretty-code-fragment\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#282c34\"},\"tabIndex\":\"0\",\"data-language\":\"python\",\"data-theme\":\"default\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"python\",\"data-theme\":\"default\",\"style\":{\"display\":\"grid\"},\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"[[\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"1.2023029\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" ]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.71759206\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.29744676\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.80767024\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]]\"}]]}]]}]}]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"On cuda:1 at mesh coordinates (batch,) = (1,):\"}],\"\\n\",[\"$\",\"div\",null,{\"data-rehype-pretty-code-fragment\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#282c34\"},\"tabIndex\":\"0\",\"data-language\":\"python\",\"data-theme\":\"default\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"python\",\"data-theme\":\"default\",\"style\":{\"display\":\"grid\"},\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"[[\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.7249529\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" ]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"1.2052361\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" ]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.80882186\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.7385298\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" ]]\"}]]}]]}]}]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"On each gpu the loss values calculated is average to get the local loss:\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"On cuda:0 at mesh coordinates (batch,) = (0,):\"}],\"\\n\",[\"$\",\"div\",null,{\"data-rehype-pretty-code-fragment\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#282c34\"},\"tabIndex\":\"0\",\"data-language\":\"python\",\"data-theme\":\"default\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"python\",\"data-theme\":\"default\",\"style\":{\"display\":\"grid\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.7562530040740967\"}]}]}]}]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"On cuda:1 at mesh coordinates (batch,) = (1,):\"}],\"\\n\",[\"$\",\"div\",null,{\"data-rehype-pretty-code-fragment\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#282c34\"},\"tabIndex\":\"0\",\"data-language\":\"python\",\"data-theme\":\"default\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"python\",\"data-theme\":\"default\",\"style\":{\"display\":\"grid\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.8693851232528687\"}]}]}]}]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":[[\"$\",\"code\",null,{\"children\":\"pmean\"}],\" is performed over 2 gpus to get the average loss for that batch of 8:\"]}]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"On cuda:0 at mesh coordinates (batch,) = (0,):\"}],\"\\n\",[\"$\",\"div\",null,{\"data-rehype-pretty-code-fragment\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#282c34\"},\"tabIndex\":\"0\",\"data-language\":\"python\",\"data-theme\":\"default\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"python\",\"data-theme\":\"default\",\"style\":{\"display\":\"grid\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.8128190636634827\"}]}]}]}]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"On cuda:1 at mesh coordinates (batch,) = (1,):\"}],\"\\n\",[\"$\",\"div\",null,{\"data-rehype-pretty-code-fragment\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#282c34\"},\"tabIndex\":\"0\",\"data-language\":\"python\",\"data-theme\":\"default\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"python\",\"data-theme\":\"default\",\"style\":{\"display\":\"grid\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.8128190636634827\"}]}]}]}]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"Final Loss returned by function:\"}]}],\"\\n\",[\"$\",\"div\",null,{\"data-rehype-pretty-code-fragment\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#282c34\"},\"tabIndex\":\"0\",\"data-language\":\"python\",\"data-theme\":\"default\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"python\",\"data-theme\":\"default\",\"style\":{\"display\":\"grid\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.81281906\"}]}]}]}]}],\"\\n\",[\"$\",\"h4\",null,{\"id\":\"implementation-of-gradients-parallelism\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"#implementation-of-gradients-parallelism\",\"children\":[\"$\",\"span\",null,{\"className\":\"icon icon-link\"}]}],\"Implementation of Gradients Parallelism:\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"For enhanced efficiency, I parallelised gradients calculation. Before gathering and averaging loss, gradients are independently computed on each GPU. Finally, the average gradients are used for the final update.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Here is the sample code (not from Maptek's codebase):\"}],\"\\n\",[\"$\",\"div\",null,{\"data-rehype-pretty-code-fragment\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#282c34\"},\"tabIndex\":\"0\",\"data-language\":\"python\",\"data-theme\":\"default\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"python\",\"data-theme\":\"default\",\"style\":{\"display\":\"grid\"},\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"from\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" functools \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"import\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" partial\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"from\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.sharding \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"import\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" NamedSharding, Mesh, PartitionSpec \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"as\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" P\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"from\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.experimental.shard_map \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"import\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" shard_map\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"from\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.experimental \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"import\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" mesh_utils\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"import\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"import\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.numpy \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"as\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jnp\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":\" \"}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"@jax\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\".\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"jit\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"def\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"loss_fn\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"params\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"batch\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"):\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\tinputs, targets \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" batch\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\tpredictions \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"predict\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(params, inputs)\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"return\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jnp.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"mean\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(jnp.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"sum\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"((predictions \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" targets)\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"**\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"2\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#E06C75\",\"fontStyle\":\"italic\"},\"children\":\"axis\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"1\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"))\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":\" \"}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"@jax\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\".\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"jit\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"def\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"get_loss_gradients\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"params\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"batch\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"):\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\tdevices \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" mes_utils.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"create_device_mesh\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"2\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",)\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\tm \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"Mesh\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(devices, (\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'batch'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",))\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"\\t@partial\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"shard_map\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#E06C75\",\"fontStyle\":\"italic\"},\"children\":\"mesh\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"mesh\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#E06C75\",\"fontStyle\":\"italic\"},\"children\":\"in_specs\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"P\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'batch'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"None\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"),\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#E06C75\",\"fontStyle\":\"italic\"},\"children\":\"out_specs\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"P\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"())\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"def\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"parallel_loss_and_gradients\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"params\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"batch\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"):\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\\tloss_local, grads_local \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"value_and_grad\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(loss_fn)(params,batch)\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\\tloss \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.lax.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"pmean\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(loss_local, \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'batch'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\")\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\\tgrads \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.lax.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"pmean\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(grads_local, \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'batch'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\")\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\\t\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"return\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" loss, grads\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"return\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"parallel_loss_and_gradients\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(params, batch)\"}]]}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Notice that the \",[\"$\",\"code\",null,{\"children\":\"value_and_grad\"}],\" function is nested inside of a \",[\"$\",\"code\",null,{\"children\":\"shard_map\"}],\". This means that no explicit sharding of the \",[\"$\",\"code\",null,{\"children\":\"loss_fn\"}],\" function is required.\"]}],\"\\n\",[\"$\",\"div\",null,{\"data-rehype-pretty-code-fragment\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#282c34\"},\"tabIndex\":\"0\",\"data-language\":\"python\",\"data-theme\":\"default\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"python\",\"data-theme\":\"default\",\"style\":{\"display\":\"grid\"},\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"@partial\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"shard_map\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#E06C75\",\"fontStyle\":\"italic\"},\"children\":\"mesh\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"mesh\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#E06C75\",\"fontStyle\":\"italic\"},\"children\":\"in_specs\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"P\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'batch'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"None\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"),\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#E06C75\",\"fontStyle\":\"italic\"},\"children\":\"out_specs\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"P\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"())\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"def\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"parallel_loss_and_gradients\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"params\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\",\"fontStyle\":\"italic\"},\"children\":\"batch\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"):\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\\tloss_local, grads_local \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"value_and_grad\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(loss_fn)(params,batch)\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\\tloss \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.lax.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"pmean\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(loss_local, \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'batch'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\")\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\\tgrads \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"=\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" jax.lax.\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"pmean\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(grads_local, \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'batch'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\")\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\\t\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"return\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" loss, grads\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"\\t\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"return\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"parallel_loss_and_gradients\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"(params, batch)\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#FFFFFF\"},\"children\":\"```\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":\" \"}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"Here \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"is\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" a demo of what this method \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#C678DD\"},\"children\":\"is\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" doing to a \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"81\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" parameter network.\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":\" \"}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"**\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"Data Labels:\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"**\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#FFFFFF\"},\"children\":\"`data_labels`\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": (\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"2\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"64\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\")\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#FFFFFF\"},\"children\":\"`data_inputs`\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": (\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"128\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"2\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\")\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":\" \"}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"**\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#61AFEF\"},\"children\":\"Sharded\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" (what each \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"GPU\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" gets):\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"**\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#FFFFFF\"},\"children\":\"`data_labels`\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": (\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"64\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\",)\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\" \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#FFFFFF\"},\"children\":\"`data_inputs`\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": (\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"64\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"2\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\")\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":\" \"}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"**\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"Before pmean:\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"**\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#FFFFFF\"},\"children\":\"```python\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"{\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"    \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'params'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"        \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'Dense_0'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'bias'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:0 at mesh coordinates (batch,) = (0,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.00814706\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.06351265\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.13132916\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"],\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:1 at mesh coordinates (batch,) = (1,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.00723927\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.05536034\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.11896412\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            },\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'kernel'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:0 at mesh coordinates (batch,) = (0,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [[\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"3.15032015e-03\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"2.28520837e-02\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"], [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]],\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:1 at mesh coordinates (batch,) = (1,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [[\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"3.8428977e-03\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"2.7929787e-02\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"], [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            }\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"        },\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"        \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'Dense_1'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'bias'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:0 at mesh coordinates (batch,) = (0,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.358499\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"],\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:1 at mesh coordinates (batch,) = (1,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.33250016\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            },\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'kernel'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:0 at mesh coordinates (batch,) = (0,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [[\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"8.91311318e-02\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"], [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"1.09796718e-01\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"], \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"],\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:1 at mesh coordinates (batch,) = (1,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [[\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.10461892\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"], [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.12866098\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"], \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            }\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"        }\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"    }\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"}\"}]}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"After pmean:\"}]}],\"\\n\",[\"$\",\"div\",null,{\"data-rehype-pretty-code-fragment\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#282c34\"},\"tabIndex\":\"0\",\"data-language\":\"python\",\"data-theme\":\"default\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"python\",\"data-theme\":\"default\",\"style\":{\"display\":\"grid\"},\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"{\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"    \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'params'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"        \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'Dense_0'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'bias'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:0 at mesh coordinates (batch,) = (0,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.00769317\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.05943649\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.12514664\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"],\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:1 at mesh coordinates (batch,) = (1,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.00769317\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.05943649\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.12514664\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            },\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'kernel'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:0 at mesh coordinates (batch,) = (0,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [[\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"3.4966089e-03\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"2.5390934e-02\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"], [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]],\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:1 at mesh coordinates (batch,) = (1,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [[\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"3.4966089e-03\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"2.5390934e-02\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\", \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"], [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            }\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"        },\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"        \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'Dense_1'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'bias'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:0 at mesh coordinates (batch,) = (0,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.34549958\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"],\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:1 at mesh coordinates (batch,) = (1,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.34549958\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            },\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'kernel'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": {\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:0 at mesh coordinates (batch,) = (0,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [[\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.09687503\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"], [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.11922885\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"], \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"],\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"                \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#98C379\"},\"children\":\"'On cuda:1 at mesh coordinates (batch,) = (1,)'\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\": [[\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.09687503\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"], [\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#56B6C2\"},\"children\":\"-\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"0.11922885\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"], \"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#D19A66\"},\"children\":\"...\"}],[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"]\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"            }\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"        }\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"    }\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"style\":{\"color\":\"#ABB2BF\"},\"children\":\"}\"}]}]]}]}]}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"2-implementation-of-vectorising-maps\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"#2-implementation-of-vectorising-maps\",\"children\":[\"$\",\"span\",null,{\"className\":\"icon icon-link\"}]}],\"2. Implementation of Vectorising Maps:\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Efforts were made to re-implement the loss function using vectorising maps to boost speed. However, no significant improvement was observed compared to native batched operations. VMAPs also consumed more memory in certain cases, leading to a shift back to native operations.\"}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"3-implementation-of-dynamic-gpu-utilisation\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"#3-implementation-of-dynamic-gpu-utilisation\",\"children\":[\"$\",\"span\",null,{\"className\":\"icon icon-link\"}]}],\"3. Implementation of Dynamic GPU Utilisation:\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Considering varying GPU architectures and quantities, I implemented functions to dynamically allocate data. This is crucial, especially for the last training step when the final batch size might differ from the predetermined size. This serves two cases: sending the last bit of data to a single GPU if it fits, or performing a search for the optimal number of GPUs for computation if it doesn't.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"JAX's high controllability comes with the cost of having to implement a lot of the things that Tensorflow automate manually. For example, if we have 4 accelerators and the last batch is odd, this will cause the entire program to fail. The way that we could combat this is to have a check function implemented where we dynamically find the optimal number of accelerators that would fit the current batch size. This is simply implemented using for loops, if statements and also using the modulo operator to determine if the batch would work with a certain amount of accelerators.\"}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"4-implementation-of-batch_size-initialisation\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"#4-implementation-of-batch_size-initialisation\",\"children\":[\"$\",\"span\",null,{\"className\":\"icon icon-link\"}]}],\"4. Implementation of batch_size Initialisation:\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The idea behind this segment is that speed should increase as the batch size that is being handled by each GPU is increased. Because of this, I have derived a function to dynamically calculate the maximum batch size that each GPU can handle. factors considered include GPU architecture, model and optimizer sizes, and data shape. This ensures maximum performance across different models and machines.\"}],\"\\n\",[\"$\",\"h4\",null,{\"id\":\"note-making-the-losses-of-the-flax-model-coherent\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"#note-making-the-losses-of-the-flax-model-coherent\",\"children\":[\"$\",\"span\",null,{\"className\":\"icon icon-link\"}]}],\"Note: Making the Losses of the Flax Model Coherent\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"To ensure consistent comparisons, every randomized aspect of the Flax model is assigned a coherent seed. However, attempts to make TensorFlow model loss coherent by seeding the data generator did not yield consistent results. This indicates internal TensorFlow parameters not being consistently initialized, resulting in varying loss compared to Flax models. As a result of this, while the speed up produced by my work is backed up by the graph produced, further work is needed to investigate the state of the Tensorflow model.\"}]]}]]}],null],\"segment\":\"__PAGE__?{\\\"slug\\\":\\\"intern\\\"}\"},\"styles\":[]}],\"segment\":[\"slug\",\"intern\",\"d\"]},\"styles\":[]}],\"segment\":\"posts\"},\"styles\":[]}]}]}],[\"$\",\"footer\",null,{\"className\":\"py-16\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-2xl px-6 lg:max-w-4xl\",\"children\":[\"$\",\"p\",null,{\"children\":[\"Built by\",\" \",[\"$\",\"$L7\",null,{\"className\":\"link\",\"href\":\"https://twitter.com/khanhgng\",\"children\":\"Khanh Nguyen\"}],[\"$\",\"br\",null,{}],[\"$\",\"$L7\",null,{\"className\":\"link\",\"href\":\"https://twitter.com/khanhgng\",\"children\":\"*inspired by Leerob\"}]]}]}]}]]}]}]}],null]}]]\n"])</script><script>self.__next_f.push([1,"4:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"How to do Parallel Training | Khanh\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"a reflection about my internship at Maptek\"}],[\"$\",\"meta\",\"3\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"link\",\"4\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"128x128\"}]]\nb:null\n"])</script></body></html>